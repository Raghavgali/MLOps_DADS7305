{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Snorkel Lab Implementation: Data Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a subset of the [IMDb movie review dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
    "Each data point is a full review of a movie, and the task is to determine whether the author wrote a\n",
    "\n",
    "* **`NEGATIVE`**: review expressing an overall negative opinion, or\n",
    "* **`POSITIVE`**: review expressing an overall positive opinion\n",
    "\n",
    "To keep the tutorial lightweight on disk and CPU, we work with a stratified sample of **5,000** reviews drawn from the full dataset.\n",
    "\n",
    "For example, the following reviews are `POSITIVE`:\n",
    "\n",
    "        \"A wonderful little production... a masterful production about one of the great masters of comedy and his life.\"\n",
    "\n",
    "        \"This was the most I'd laughed at one of Woody's comedies in years... a great comedy to go see with friends.\"\n",
    "\n",
    "and these are `NEGATIVE`:\n",
    "\n",
    "        \"Basically there's a family where a little boy thinks there's a zombie in his closet... suddenly, Jake decides to become Rambo and kill the zombie.\"\n",
    "\n",
    "        \"This movie is slower than a soap opera... 3 out of 10 just for the well playing parents.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splits in Snorkel\n",
    "\n",
    "We split our data into two sets:\n",
    "* **Training Set**: The largest split of the dataset, and the one without any ground truth (\"gold\") labels.\n",
    "We will generate labels for these data points with weak supervision.\n",
    "* **Test Set**: A small, standard held-out blind hand-labeled set for final evaluation of our classifier. This set should only be used for final evaluation, _not_ error analysis.\n",
    "\n",
    "Note that in more advanced production settings, we will often further split up the available hand-labeled data into a _development split_, for getting ideas to write labeling functions, and a _validation split_ for e.g. checking our performance without looking at test set scores, hyperparameter tuning, etc.  These splits are used in some of the other advanced tutorials, but omitted for simplicity here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the IMDb reviews dataset and create Pandas DataFrame objects for the train and test sets.\n",
    "DataFrames are extremely popular in Python data analysis workloads, and Snorkel provides native support\n",
    "for several DataFrame-like data structures, including Pandas, Dask, and PySpark.\n",
    "For more information on working with Pandas DataFrames, see the [Pandas DataFrame guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html).\n",
    "\n",
    "Each DataFrame consists of the following fields:\n",
    "* **`text`**: Raw text content of the movie review\n",
    "* **`label`**: Whether the review is `POSITIVE` (1), `NEGATIVE` (0), or `UNKNOWN/ABSTAIN` (-1) when generated by LFs\n",
    "\n",
    "We start by loading the full CSV export of the IMDb dataset, downsampling it to 5,000 stratified examples for faster experimentation, and then creating randomized train and test splits from that subset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "This next cell takes care of some notebook-specific housekeeping.\n",
    "You can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# Turn off TensorFlow logging messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "If you want to display all review text untruncated, change `DISPLAY_ALL_TEXT` to `True` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DISPLAY_ALL_TEXT = False\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0 if DISPLAY_ALL_TEXT else 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "This next cell makes sure a spaCy English model is downloaded.\n",
    "If this is your first time downloading this model, restart the kernel after executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true,
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Download the spaCy english model\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "MAX_DATASET_SIZE = 5000\n",
    "\n",
    "data_path = Path(\"Lab3_assignment/data/IMDB Dataset.csv\")\n",
    "\n",
    "df = pd.read_csv(\"/Users/raghavg/Desktop/MLOps/Lab3_assignment/data/IMDB Dataset.csv\")\n",
    "df[\"text\"] = (\n",
    "    df[\"review\"]\n",
    "    .str.replace(\"<br />\", \" \", regex=False)\n",
    "    .str.replace(\"<br/>\", \" \", regex=False)\n",
    "    .str.replace(\"<br>\", \" \", regex=False)\n",
    "    .str.strip()\n",
    ")\n",
    "df[\"label\"] = df[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "if len(df) > MAX_DATASET_SIZE:\n",
    "    df, _ = train_test_split(\n",
    "        df,\n",
    "        train_size=MAX_DATASET_SIZE,\n",
    "        stratify=df[\"label\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[\"label\"], random_state=42\n",
    ")\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "Y_test = df_test.label.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class distribution varies slightly between `POSITIVE` and `NEGATIVE`, but they're approximately class-balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For clarity, we define constants to represent the class labels for negative, positive, and abstaining.\n",
    "ABSTAIN = -1\n",
    "NEGATIVE = 0\n",
    "POSITIVE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing Labeling Functions (LFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A gentle introduction to LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling functions (LFs) help users encode domain knowledge and other supervision sources programmatically.**\n",
    "\n",
    "LFs are heuristics that take as input a data point and either assign a label to it (in this case, `NEGATIVE` or `POSITIVE`) or abstain (don't assign any label). Labeling functions can be *noisy*: they don't have perfect accuracy and don't have to label every data point.\n",
    "Moreover, different labeling functions can overlap (label the same data point) and even conflict (assign different labels to the same data point). This is expected, and we demonstrate how we deal with this later.\n",
    "\n",
    "Because their only requirement is that they map a data point a label (or abstain), they can wrap a wide variety of forms of supervision. Examples include, but are not limited to:\n",
    "* *Keyword searches*: looking for specific words in a sentence\n",
    "* *Pattern matching*: looking for specific syntactical patterns\n",
    "* *Third-party models*: using an pre-trained model (usually a model for a different task than the one at hand)\n",
    "* *Distant supervision*: using external knowledge base\n",
    "* *Crowdworker labels*: treating each crowdworker as a black-box function that assigns labels to subsets of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended practice for LF development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical LF development cycles include multiple iterations of ideation, refining, evaluation, and debugging.\n",
    "A typical cycle consists of the following steps:\n",
    "\n",
    "1. Look at examples to generate ideas for LFs\n",
    "1. Write an initial version of an LF\n",
    "1. Spot check its performance by looking at its output on data points in the training set (or development set if available)\n",
    "1. Refine and debug to improve coverage or accuracy as necessary\n",
    "\n",
    "Our goal for LF development is to create a high quality set of training labels for our unlabeled dataset,\n",
    "not to label everything or directly create a model for inference using the LFs.\n",
    "The training labels are used to train a separate discriminative model (in this case, one which just uses the review text) in order to generalize to new, unseen data points.\n",
    "Using this model, we can make predictions for data points that our LFs don't cover.\n",
    "\n",
    "We'll walk through the development of two LFs using basic analysis tools in Snorkel, then provide a full set of LFs that we developed for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Exploring the training set for initial ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by looking at 20 random data points from the `train` set to generate some ideas for LFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The three names that mean the most to this fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Let me ask you one more question\" Ha ! what a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This was playing at our theater in Amsterdam a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A different look at horror. The styling differ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is a waste of film stock. Do you be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  The three names that mean the most to this fil...      1\n",
       "1  \"Let me ask you one more question\" Ha ! what a...      1\n",
       "2  This was playing at our theater in Amsterdam a...      1\n",
       "3  A different look at horror. The styling differ...      0\n",
       "4  This movie is a waste of film stock. Do you be...      0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>This film has an excellent premise and is real...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>I have always been a huge fan of \"Homicide: Li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>The Israeli/Palestinian conflict persists and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>John Cassavetes is on the run from the law. He...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>Were it not for the fact that this came as a 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>Having looked at some of the other comments he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>This film would be considered controversial to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>I walked into a book store in Brentwood, Tenne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>This was recommended to me by a friend that sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Don't you ever miss the good old days when Dis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>This series is vastly underrated. Like many ot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>So what is one to do if you are a porno star w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>This movie started slowly, then gained momentu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>It is high time that American critics and fans...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Sly Stallone is hardly the finest actor in the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>Of course, really experienced reviewers who li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>This movie is truly amazing,over the years I h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Gen-Y Cops...since I heard of the film being i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>I turned this off within the first five minute...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Based on the true story of two young Americans...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "3846  This film has an excellent premise and is real...      1\n",
       "848   I have always been a huge fan of \"Homicide: Li...      1\n",
       "1658  The Israeli/Palestinian conflict persists and ...      1\n",
       "3415  John Cassavetes is on the run from the law. He...      1\n",
       "3678  Were it not for the fact that this came as a 2...      0\n",
       "3088  Having looked at some of the other comments he...      1\n",
       "218   This film would be considered controversial to...      1\n",
       "2311  I walked into a book store in Brentwood, Tenne...      0\n",
       "1733  This was recommended to me by a friend that sa...      1\n",
       "998   Don't you ever miss the good old days when Dis...      1\n",
       "619   This series is vastly underrated. Like many ot...      1\n",
       "3940  So what is one to do if you are a porno star w...      0\n",
       "655   This movie started slowly, then gained momentu...      1\n",
       "1970  It is high time that American critics and fans...      0\n",
       "476   Sly Stallone is hardly the finest actor in the...      0\n",
       "3105  Of course, really experienced reviewers who li...      1\n",
       "1881  This movie is truly amazing,over the years I h...      0\n",
       "317   Gen-Y Cops...since I heard of the film being i...      1\n",
       "773   I turned this off within the first five minute...      0\n",
       "1991  Based on the true story of two young Americans...      0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"text\", \"label\"]].sample(20, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One dominant pattern in the most enthusiastic reviews (which we might know from prior domain experience, or from inspecting a few training data points) is the use of the phrase \"loved it\" (e.g. \"absolutely loved it\").\n",
    "Let's start with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Writing an LF to identify enthusiastic reviews that mention `\"loved it\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling functions in Snorkel are created with the\n",
    "[`@labeling_function` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.labeling_function.html).\n",
    "The [decorator](https://realpython.com/primer-on-python-decorators/) can be applied to _any Python function_ that returns a label for a single data point.\n",
    "\n",
    "Let's start developing an LF to catch instances of reviewers explicitly stating that they loved the movie.\n",
    "We'll start by just looking for the exact string `\"loved it\"` in the text, and see how that compares to looking for just `\"love\"` in the text.\n",
    "For the two versions of our rule, we'll write a Python function over a single data point that express it, then add the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def mentions_love(x):\n",
    "    return POSITIVE if \"love\" in x.text.lower() else ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def mentions_loved_it(x):\n",
    "    return POSITIVE if \"loved it\" in x.text.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "os.environ.setdefault(\"JOBLIB_MULTIPROCESSING\", \"0\")\n",
    "\n",
    "def apply_lfs_sequentially(\n",
    "    lfs,\n",
    "    df,\n",
    "    *,\n",
    "    batch_size=512,\n",
    "    keep_cols=None,\n",
    "    show_progress=False,\n",
    "):\n",
    "    \"\"\"Apply labeling functions in batches to cap temporary disk usage.\"\"\"\n",
    "    if keep_cols is not None:\n",
    "        keep_cols = tuple(keep_cols)\n",
    "\n",
    "    applier = PandasLFApplier(lfs=lfs)\n",
    "    label_chunks = []\n",
    "    total = len(df)\n",
    "\n",
    "    for start in range(0, total, batch_size):\n",
    "        stop = min(start + batch_size, total)\n",
    "        batch = df.iloc[start:stop]\n",
    "        if keep_cols is not None:\n",
    "            batch = batch.loc[:, list(keep_cols)]\n",
    "\n",
    "        label_matrix = applier.apply(df=batch, progress_bar=False)\n",
    "        label_chunks.append(label_matrix)\n",
    "\n",
    "        if show_progress:\n",
    "            print(f\"Applied LFs to rows {start}:{stop} of {total}\")\n",
    "\n",
    "    if not label_chunks:\n",
    "        return np.zeros((0, len(lfs)), dtype=int)\n",
    "\n",
    "    return np.vstack(label_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply one or more LFs that we've written to a collection of data points, we use an\n",
    "[`LFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFApplier.html).\n",
    "Because our data points are represented with a Pandas DataFrame in this tutorial, we use the\n",
    "[`PandasLFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.PandasLFApplier.html).\n",
    "Correspondingly, a single data point `x` that's passed into our LFs will be a [Pandas `Series` object](https://pandas.pydata.org/pandas-docs/stable/reference/series.html).\n",
    "\n",
    "It's important to note that these LFs will work for any object with an attribute named `text`, not just Pandas objects.\n",
    "Snorkel has several other appliers for different data point collection types which you can browse in the [API documentation](https://snorkel.readthedocs.io/en/master/packages/labeling.html).\n",
    "\n",
    "The output of the `apply(...)` method is a ***label matrix***, a fundamental concept in Snorkel.\n",
    "It's a NumPy array `L` with one column for each LF and one row for each data point, where `L[i, j]` is the label that the `j`th labeling function output for the `i`th data point.\n",
    "We'll create a label matrix for the `train` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "lfs = [mentions_loved_it, mentions_love]\n",
    "L_train = apply_lfs_sequentially(lfs=lfs, df=df_train, keep_cols=(\"text\",))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1],\n",
       "       [-1, -1],\n",
       "       [-1, -1],\n",
       "       ...,\n",
       "       [-1,  1],\n",
       "       [-1, -1],\n",
       "       [-1, -1]], shape=(4000, 2))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Evaluate performance on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily calculate the coverage of these LFs (i.e., the percentage of the dataset that they label) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mentions_loved_it coverage: 1.200000%\n",
      "mentions_love coverage: 25.600000%\n"
     ]
    }
   ],
   "source": [
    "coverage_mentions_loved_it, coverage_mentions_love = (L_train != ABSTAIN).mean(axis=0)\n",
    "print(f\"mentions_loved_it coverage: {coverage_mentions_loved_it * 100:.6f}%\")\n",
    "print(f\"mentions_love coverage: {coverage_mentions_love * 100:.6f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of statistics about labeling functions &mdash; like coverage &mdash; are useful when building any Snorkel application.\n",
    "So Snorkel provides tooling for common LF analyses using the\n",
    "[`LFAnalysis` utility](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html).\n",
    "We report the following summary statistics for multiple LFs at once:\n",
    "\n",
    "* **Polarity**: The set of unique labels this LF outputs (excluding abstains)\n",
    "* **Coverage**: The fraction of the dataset the LF labels\n",
    "* **Overlaps**: The fraction of the dataset where this LF and at least one other LF label\n",
    "* **Conflicts**: The fraction of the dataset where this LF and at least one other LF label and disagree\n",
    "* **Correct**: The number of data points this LF labels correctly (if gold labels are provided)\n",
    "* **Incorrect**: The number of data points this LF labels incorrectly (if gold labels are provided)\n",
    "* **Empirical Accuracy**: The empirical accuracy of this LF (if gold labels are provided)\n",
    "\n",
    "For *Correct*, *Incorrect*, and *Empirical Accuracy*, we don't want to penalize the LF for data points where it abstained.\n",
    "We calculate these statistics only over those data points where the LF output a label.\n",
    "**Note that in our current setup, we can't compute these statistics because we don't have any ground-truth labels (other than in the test set, which we cannot look at). Not to worryâ€”Snorkel's `LabelModel` will estimate them without needing any ground-truth labels in the next step!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mentions_loved_it</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentions_love</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "mentions_loved_it  0      [1]     0.012     0.012        0.0\n",
       "mentions_love      1      [1]     0.256     0.012        0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to pick the broader `mentions_love` rule, since it has higher coverage. Let's take a look at 10 random `train` set data points where `mentions_love` labeled `POSITIVE` to see if it matches our intuition or if we can identify some false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>In this swimming pool, this pond, there are wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>Disney, the film name that once stood for all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>I don't remember when I first heard about this...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>When the noble Hanabusa clan is decimated by t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>This would have been my number one movie of th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>I was in a bad frame of mind when I first saw ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>This is as good as it gets.  This is six episo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>First of all, I too was expecting another Hero...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>How does a Scotsman in a kilt make love in the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>I guess this is in the public domain as its ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "3230  In this swimming pool, this pond, there are wa...      1\n",
       "3089  Disney, the film name that once stood for all ...      1\n",
       "1919  I don't remember when I first heard about this...      1\n",
       "3187  When the noble Hanabusa clan is decimated by t...      1\n",
       "3345  This would have been my number one movie of th...      1\n",
       "428   I was in a bad frame of mind when I first saw ...      1\n",
       "112   This is as good as it gets.  This is six episo...      1\n",
       "3855  First of all, I too was expecting another Hero...      0\n",
       "2839  How does a Scotsman in a kilt make love in the...      0\n",
       "3054  I guess this is in the public domain as its ou...      0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[L_train[:, 1] == POSITIVE].sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clear false positives here, but many look like they could be labeled by `mentions_loved_it` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>Frankly, after Cotton club and Unfaithful, it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>The original The Man Who Knew Too Much brought...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>This has to be, hands down, hats off, one of t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I would rate this film high on my list of Ingr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>While filming an 80's horror movie called 'Hot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>EXCUSE ME!!! HellOOOOOOOOOO!!!!!!!!!!! CUBA GO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>Dan Finnerty and the Dan Band are so-o-o-o-o-o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>On 24 October 1955, the hard-work geologist of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>(spoilers) Horrifyingly enough, I have actuall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>I quote below words from my favor writer, Paul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "3835  Frankly, after Cotton club and Unfaithful, it ...      0\n",
       "2909  The original The Man Who Knew Too Much brought...      1\n",
       "2138  This has to be, hands down, hats off, one of t...      1\n",
       "17    I would rate this film high on my list of Ingr...      1\n",
       "1063  While filming an 80's horror movie called 'Hot...      0\n",
       "1433  EXCUSE ME!!! HellOOOOOOOOOO!!!!!!!!!!! CUBA GO...      1\n",
       "2729  Dan Finnerty and the Dan Band are so-o-o-o-o-o...      1\n",
       "677   On 24 October 1955, the hard-work geologist of...      1\n",
       "3984  (spoilers) Horrifyingly enough, I have actuall...      0\n",
       "710   I quote below words from my favor writer, Paul...      1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.analysis import get_label_buckets\n",
    "\n",
    "buckets = get_label_buckets(L_train[:, 0], L_train[:, 1])\n",
    "df_train.iloc[buckets[(ABSTAIN, POSITIVE)]].sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these seem like small variations of \"loved it\", like \"love it\" or \"love this\". Can we get the best of both worlds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Balance accuracy and coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can use regular expressions to capture phrases such as \"not really good\" or \"not worth it\" to complement our keyword rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def regex_not_good(x):\n",
    "    return NEGATIVE if re.search(r\"not\\s+(really\\s+)?(good|great|worth)\", x.text, flags=re.I) else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's generate our label matrices and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "lfs = [mentions_loved_it, mentions_love, regex_not_good]\n",
    "L_train = apply_lfs_sequentially(lfs=lfs, df=df_train, keep_cols=(\"text\",))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mentions_loved_it</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentions_love</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>0.00275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_not_good</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.00275</td>\n",
       "      <td>0.00275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "mentions_loved_it  0      [1]     0.012   0.01200    0.00000\n",
       "mentions_love      1      [1]     0.256   0.01475    0.00275\n",
       "regex_not_good     2      [0]     0.015   0.00275    0.00275"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've split the difference in `train` set coverageâ€”this looks promising!\n",
    "Let's verify that we corrected our false positive from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the coverage difference between `mentions_love` and `regex_not_good`, let's take a look at 10 data points from the `train` set. Remember: coverage is only helpful when it does not introduce too many false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>I love this film...! I've seen it 1000 x on dv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>It's too bad iameracing wants to deny the real...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>How truly friendly, charming and cordial is th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>I don't see that much wrong with this movie. G...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>It's a long time ago I saw this movie and stil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>I enjoyed this movie a lot. I thought that the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>A deplorable social condition triggers off the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>The movie was very sweet and heartwarming! I c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>Reading some of the other reviews of this film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Loved the shots of airports -- Dallas, Phoenix...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "3640  I love this film...! I've seen it 1000 x on dv...      1\n",
       "2440  It's too bad iameracing wants to deny the real...      1\n",
       "1217  How truly friendly, charming and cordial is th...      1\n",
       "1982  I don't see that much wrong with this movie. G...      1\n",
       "3851  It's a long time ago I saw this movie and stil...      0\n",
       "1027  I enjoyed this movie a lot. I thought that the...      1\n",
       "2827  A deplorable social condition triggers off the...      1\n",
       "3615  The movie was very sweet and heartwarming! I c...      1\n",
       "1368  Reading some of the other reviews of this film...      1\n",
       "215   Loved the shots of airports -- Dallas, Phoenix...      1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = get_label_buckets(L_train[:, 1], L_train[:, 2])\n",
    "df_train.iloc[buckets[(POSITIVE, ABSTAIN)]].sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these are POSITIVE, but a good number are false positives.\n",
    "**To keep precision high (while not sacrificing much in terms of coverage), we'd choose our regex-based rule.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Writing an LF that uses a third-party model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LF interface is extremely flexible, and can wrap existing models.\n",
    "A common technique is to use a commodity model trained for other tasks that are related to, but not the same as, the one we care about.\n",
    "\n",
    "For example, the [TextBlob](https://textblob.readthedocs.io/en/dev/index.html) tool provides a pretrained sentiment analyzer.\n",
    "Our task uses that same polarity signal, but we may want to set thresholds tailored to our dataset for positive and negatives.\n",
    "\n",
    "**A brief intro to `Preprocessor`s**\n",
    "\n",
    "A [Snorkel `Preprocessor`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.Preprocessor.html#snorkel.preprocess.Preprocessor)\n",
    "is constructed from a black-box Python function that maps a data point to a new data point.\n",
    "`LabelingFunction`s can use `Preprocessor`s, which lets us write LFs over transformed or enhanced data points.\n",
    "We add the [`@preprocessor(...)` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.preprocessor.html)\n",
    "to preprocessing functions to create `Preprocessor`s.\n",
    "`Preprocessor`s also have extra functionality, such as memoization\n",
    "(i.e. input/output caching, so it doesn't re-execute for each LF that uses it).\n",
    "\n",
    "We'll start by creating a `Preprocessor` that runs `TextBlob` on our reviews, then extracts the polarity and subjectivity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=False)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pick a reasonable threshold and write a corresponding labeling function (note that it doesn't have to be perfect as the `LabelModel` will soon help us estimate each labeling function's accuracy and reweight their outputs accordingly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_positive(x):\n",
    "    return POSITIVE if x.polarity >= 0.35 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the subjectivity scores.\n",
    "This will run faster than the last cell, since we memoized the `Preprocessor` outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_negative(x):\n",
    "    return NEGATIVE if x.polarity <= -0.25 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our LFs so we can analyze their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "lfs = [textblob_positive, textblob_negative]\n",
    "L_train = apply_lfs_sequentially(lfs=lfs, df=df_train, keep_cols=(\"text\",))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>textblob_positive</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.05950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_negative</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "textblob_positive  0      [1]   0.05950       0.0        0.0\n",
       "textblob_negative  1      [0]   0.01775       0.0        0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_train, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again, these LFs aren't perfectâ€”note that the `textblob_negative` LF has fairly high coverage and could have a high rate of false positives. We'll rely on Snorkel's `LabelModel` to estimate the labeling function accuracies and reweight and combine their outputs accordingly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Writing More Labeling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a single LF had high enough coverage to label our entire test dataset accurately, then we wouldn't need a classifier at all.\n",
    "We could just use that single simple heuristic to complete the task.\n",
    "But most problems are not that simple.\n",
    "Instead, we usually need to **combine multiple LFs** to label our dataset, both to increase the size of the generated training set (since we can't generate training labels for data points that no LF voted on) and to improve the overall accuracy of the training labels we generate by factoring in multiple different signals.\n",
    "\n",
    "In the following sections, we'll show just a few of the many types of LFs that you could write to generate a training dataset for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Keyword LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For text applications, some of the simplest LFs to write are often just keyword lookups.\n",
    "These will often follow the same execution pattern, so we can create a template and use the `resources` parameter to pass in LF-specific keywords.\n",
    "Similar to the [`labeling_function` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.labeling_function.html#snorkel.labeling.labeling_function),\n",
    "the [`LabelingFunction` class](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LabelingFunction.html#snorkel.labeling.LabelingFunction)\n",
    "wraps a Python function (the `f` parameter), and we can use the `resources` parameter to pass in keyword arguments (here, our keywords to lookup) to said function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(name, keywords, label):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{name}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "\n",
    "keyword_amazing = make_keyword_lf(\n",
    "    name=\"amazing\",\n",
    "    keywords=[\"amazing\", \"excellent\", \"fantastic\", \"incredible\"],\n",
    "    label=POSITIVE,\n",
    ")\n",
    "\n",
    "keyword_heart = make_keyword_lf(\n",
    "    name=\"heart\",\n",
    "    keywords=[\"heartwarming\", \"touching\", \"moving\"],\n",
    "    label=POSITIVE,\n",
    ")\n",
    "\n",
    "keyword_worth = make_keyword_lf(\n",
    "    name=\"worth\",\n",
    "    keywords=[\"worth watching\", \"worthwhile\"],\n",
    "    label=POSITIVE,\n",
    ")\n",
    "\n",
    "keyword_worst = make_keyword_lf(\n",
    "    name=\"worst\",\n",
    "    keywords=[\"worst\", \"awful\", \"terrible\", \"horrible\"],\n",
    "    label=NEGATIVE,\n",
    ")\n",
    "\n",
    "keyword_boring = make_keyword_lf(\n",
    "    name=\"boring\",\n",
    "    keywords=[\"boring\", \"dull\", \"slow\", \"lifeless\"],\n",
    "    label=NEGATIVE,\n",
    ")\n",
    "\n",
    "keyword_waste = make_keyword_lf(\n",
    "    name=\"waste\",\n",
    "    keywords=[\"waste of time\", \"wasted my time\", \"waste time\"],\n",
    "    label=NEGATIVE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Pattern-matching LFs (regular expressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a little more control over a keyword search, we can look for regular expressions instead.\n",
    "The LF we developed above (`regex_not_good`) is an example of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)  Heuristic LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be other heuristics or \"rules of thumb\" that you come up with as you look at the data.\n",
    "So long as you can express it in a function, it's a viable LF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def short_review(x):\n",
    "    \"\"\"Very short reviews tend to be negative reactions.\"\"\"\n",
    "    return NEGATIVE if len(x.text.split()) < 7 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) LFs with Complex Preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some LFs rely on fields that aren't present in the raw data, but can be derived from it.\n",
    "We can enrich our data (providing more fields for the LFs to refer to) using `Preprocessor`s.\n",
    "\n",
    "For example, we can use the fantastic NLP (natural language processing) tool [spaCy](https://spacy.io/) to add lemmas, part-of-speech (pos) tags, etc. to each token.\n",
    "Snorkel provides a prebuilt preprocessor for spaCy called `SpacyPreprocessor` which adds a new field to the\n",
    "data point containing a [spaCy `Doc` object](https://spacy.io/api/doc).\n",
    "For more info, see the [`SpacyPreprocessor` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.nlp.SpacyPreprocessor.html#snorkel.preprocess.nlp.SpacyPreprocessor).\n",
    "\n",
    "\n",
    "If you prefer to use a different NLP tool, you can also wrap that as a `Preprocessor` and use it in the same way.\n",
    "For more info, see the [`preprocessor` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.preprocessor.html#snorkel.preprocess.preprocessor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "If the spaCy English model wasn't already installed, the next cell may raise an exception.\n",
    "If this happens, restart the kernel and re-execute the cells up to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "# The SpacyPreprocessor parses the text in text_field and\n",
    "# stores the new enriched representation in doc_field\n",
    "spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def mentions_character(x):\n",
    "    \"\"\"Longer reviews that mention specific people often highlight positive performances.\"\"\"\n",
    "    if len(x.doc) > 30 and any(ent.label_ == \"PERSON\" for ent in x.doc.ents):\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because spaCy is such a common preprocessor for NLP applications, we also provide a\n",
    "[prebuilt `labeling_function`-like decorator that uses spaCy](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.lf.nlp.nlp_labeling_function.html#snorkel.labeling.lf.nlp.nlp_labeling_function).\n",
    "This resulting LF is identical to the one defined manually above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.lf.nlp import nlp_labeling_function\n",
    "\n",
    "\n",
    "@nlp_labeling_function()\n",
    "def mentions_character_nlp(x):\n",
    "    \"\"\"Longer reviews that mention specific people often highlight positive performances.\"\"\"\n",
    "    if len(x.doc) > 30 and any(ent.label_ == \"PERSON\" for ent in x.doc.ents):\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding new domain-specific preprocessors and LF types is a great way to contribute to Snorkel!\n",
    "If you have an idea, feel free to reach out to the maintainers or submit a PR!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Third-party Model LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also utilize other models, including ones trained for other tasks that are related to, but not the same as, the one we care about.\n",
    "The TextBlob-based LFs we created above are great examples of this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combining Labeling Function Outputs with the Label Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates just a handful of the types of LFs that one might write for this task.\n",
    "One of the key goals of Snorkel is _not_ to replace the effort, creativity, and subject matter expertise required to come up with these labeling functions, but rather to make it faster to write them, since **in Snorkel the labeling functions are assumed to be noisy, i.e. innaccurate, overlapping, etc.**\n",
    "Said another way: the LF abstraction provides a flexible interface for conveying a huge variety of supervision signals, and the `LabelModel` is able to denoise these signals, reducing the need for painstaking manual fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [\n",
    "    mentions_loved_it,\n",
    "    mentions_love,\n",
    "    regex_not_good,\n",
    "    keyword_amazing,\n",
    "    keyword_heart,\n",
    "    keyword_worth,\n",
    "    keyword_worst,\n",
    "    keyword_boring,\n",
    "    keyword_waste,\n",
    "    short_review,\n",
    "    mentions_character,\n",
    "    mentions_character_nlp,\n",
    "    textblob_positive,\n",
    "    textblob_negative,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our full set of LFs, we can now apply these once again with `LFApplier` to get the label matrices.\n",
    "The Pandas format provides an easy interface that many practitioners are familiar with, but it is also less optimized for scale.\n",
    "For larger datasets, more compute-intensive LFs, or larger LF sets, you may decide to use one of the other data formats\n",
    "that Snorkel supports natively, such as Dask DataFrames or PySpark DataFrames, and their corresponding applier objects.\n",
    "For more info, check out the [Snorkel API documentation](https://snorkel.readthedocs.io/en/master/packages/labeling.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "L_train = apply_lfs_sequentially(lfs=lfs, df=df_train, keep_cols=(\"text\",))\n",
    "L_test = apply_lfs_sequentially(lfs=lfs, df=df_test, keep_cols=(\"text\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mentions_loved_it</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.00150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentions_love</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.25600</td>\n",
       "      <td>0.23850</td>\n",
       "      <td>0.06925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_not_good</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.01350</td>\n",
       "      <td>0.01225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_amazing</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.15575</td>\n",
       "      <td>0.14625</td>\n",
       "      <td>0.03550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_heart</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04875</td>\n",
       "      <td>0.04575</td>\n",
       "      <td>0.01425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_worth</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.02075</td>\n",
       "      <td>0.00800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_worst</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.19625</td>\n",
       "      <td>0.17150</td>\n",
       "      <td>0.16325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_boring</th>\n",
       "      <td>7</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.12125</td>\n",
       "      <td>0.11625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_waste</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.01550</td>\n",
       "      <td>0.01325</td>\n",
       "      <td>0.01150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_review</th>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentions_character</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.81500</td>\n",
       "      <td>0.81500</td>\n",
       "      <td>0.25300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentions_character_nlp</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.81500</td>\n",
       "      <td>0.81500</td>\n",
       "      <td>0.25300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_positive</th>\n",
       "      <td>12</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.05950</td>\n",
       "      <td>0.05425</td>\n",
       "      <td>0.00175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_negative</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>0.01700</td>\n",
       "      <td>0.01250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j Polarity  Coverage  Overlaps  Conflicts\n",
       "mentions_loved_it        0      [1]   0.01200   0.01200    0.00150\n",
       "mentions_love            1      [1]   0.25600   0.23850    0.06925\n",
       "regex_not_good           2      [0]   0.01500   0.01350    0.01225\n",
       "keyword_amazing          3      [1]   0.15575   0.14625    0.03550\n",
       "keyword_heart            4      [1]   0.04875   0.04575    0.01425\n",
       "keyword_worth            5      [1]   0.02250   0.02075    0.00800\n",
       "keyword_worst            6      [0]   0.19625   0.17150    0.16325\n",
       "keyword_boring           7      [0]   0.13300   0.12125    0.11625\n",
       "keyword_waste            8      [0]   0.01550   0.01325    0.01150\n",
       "short_review             9       []   0.00000   0.00000    0.00000\n",
       "mentions_character      10      [1]   0.81500   0.81500    0.25300\n",
       "mentions_character_nlp  11      [1]   0.81500   0.81500    0.25300\n",
       "textblob_positive       12      [1]   0.05950   0.05425    0.00175\n",
       "textblob_negative       13      [0]   0.01775   0.01700    0.01250"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "We see that our labeling functions vary in coverage, how much they overlap/conflict with one another, and almost certainly their accuracies as well.\n",
    "We can view a histogram of how many LF labels the data points in our train set have to get an idea of our total coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMUVJREFUeJzt3Qd8VGW+//FfAiShhbIRQpNQIhGlhl4WvLCU5VquZYFFqQsriCJICbtCcMGlLE3KJYKi4iJEX6tYQFT67koTEEQpUYMJLTRJIEgCZO7r9/z/M5shE0xwwgzzfN6v15E5Z86ceeYIk2+eGuRwOBwCAABgkWBfFwAAAOBWIwABAADrEIAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFinuK8L4I9ycnLk+PHjUrZsWQkKCvJ1cQAAQAHo1IYXLlyQqlWrSnDwjet4CEAeaPipUaNGQe41AADwM6mpqVK9evUbnkMA8kBrfpw3MDw8vGj+7wAAAK/KyMgwFRjOn+M3QgDywNnspeGHAAQAwO2lIN1X6AQNAACsQwACAADWIQABAADrEIAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDoEIAAAYB0CEAAAsE5xXxcAUFFxq7kR1zkyrQf3BACKCDVAAADAOgQgAABgHQIQAACwDgEIAABYhwAEAACsQwACAADWIQABAADrEIAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDoEIAAAYB0CEAAAsA4BCAAAWIcABAAArEMAAgAA1vGLALRw4UKJioqSsLAwadmypezYsSPfc999911p1qyZlC9fXkqXLi2NGzeWN9980+0ch8MhEydOlCpVqkjJkiWlc+fOkpSUdAs+CQAAuB34PAAlJibKqFGjJD4+Xnbv3i2NGjWSrl27yqlTpzyeX7FiRfnzn/8sW7dulX379smAAQPM9sknn7jOmTFjhsybN08SEhJk+/btJijpNS9fvnwLPxkAAPBXQQ6tLvEhrfFp3ry5LFiwwOzn5ORIjRo15Omnn5a4uLgCXaNp06bSo0cPmTx5sqn9qVq1qjz33HMyevRo83x6erpUrlxZXn/9denVq1ee12dlZZnNKSMjw5RBXxceHu61z4r8RcWt5vZc58i0HtwTACgE/fldrly5Av389mkNUHZ2tuzatcs0UbkKFBxs9rWG5+do2Fm/fr0cOnRIfv3rX5tjycnJcvLkSbdr6s3QoJXfNadOnWrOcW4afgAAQODyaQA6c+aMXLt2zdTO5Kb7GmLyo8muTJkyEhISYmp+5s+fL7/5zW/Mc87XFeaa48ePN9d0bqmpqV74dAAAwF8Vl9tQ2bJl5csvv5SLFy+aGiDtQ1S7dm3p2LHjTV0vNDTUbAAAwA4+DUARERFSrFgxSUtLczuu+5GRkfm+TpvJ6tatax7rKLADBw6YZiwNQM7X6TV0FFjua+q5AAAAPm0C0yas2NhYU4vjpJ2gdb9169YFvo6+xtmJuVatWiYE5b6mdorS0WCFuSYAAAhcPm8C0+arfv36mbl9WrRoIXPnzpXMzEwztF317dtXqlWrZmp4lP6p59apU8eEnjVr1ph5gBYtWmSeDwoKkmeffVamTJki0dHRJhBNmDDBjAx76KGHfPpZAQCAf/B5AOrZs6ecPn3aTFyonZS1mWrt2rWuTswpKSmmyctJw9GwYcPk6NGjZpLDmJgY+fvf/26u4zR27Fhz3pAhQ+T8+fPSrl07c02daBEAAMDn8wDd7vMIwDuYBygv5gECgACdBwgAAMAXCEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDoEIAAAYB0CEAAAsA4BCAAAWIcABAAArEMAAgAA1iEAAQAA6xCAAACAdQhAAADAOgQgAABgHQIQAACwDgEIAABYhwAEAACsQwACAADWIQABAADrEIAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDoEIAAAYB0CEAAAsA4BCAAAWIcABAAArEMAAgAA1iEAAQAA6xCAAACAdQhAAADAOgQgAABgHb8IQAsXLpSoqCgJCwuTli1byo4dO/I9d8mSJdK+fXupUKGC2Tp37pzn/P79+0tQUJDb1q1bt1vwSQAAwO3A5wEoMTFRRo0aJfHx8bJ7925p1KiRdO3aVU6dOuXx/E2bNknv3r1l48aNsnXrVqlRo4Z06dJFjh075naeBp4TJ064thUrVtyiTwQAAPydzwPQ7NmzZfDgwTJgwACpX7++JCQkSKlSpWTp0qUez1++fLkMGzZMGjduLDExMfLKK69ITk6OrF+/3u280NBQiYyMdG1aWwQAAODzAJSdnS27du0yzVhOwcHBZl9rdwri0qVLcuXKFalYsWKemqJKlSpJvXr1ZOjQoXL27Nl8r5GVlSUZGRluGwAACFw+DUBnzpyRa9euSeXKld2O6/7JkycLdI1x48ZJ1apV3UKUNn8tW7bM1ApNnz5dNm/eLN27dzfv5cnUqVOlXLlyrk2b1QAAQOAqLrexadOmycqVK01tj3agdurVq5frcYMGDaRhw4ZSp04dc16nTp3yXGf8+PGmH5KT1gARggAACFw+rQGKiIiQYsWKSVpamttx3dd+Ozcyc+ZME4A+/fRTE3BupHbt2ua9vv32W4/Pa3+h8PBwtw0AAAQunwagkJAQiY2NdevA7OzQ3Lp163xfN2PGDJk8ebKsXbtWmjVr9rPvc/ToUdMHqEqVKl4rOwAAuH35fBSYNj3p3D5vvPGGHDhwwHRYzszMNKPCVN++fU0TlZP26ZkwYYIZJaZzB2lfId0uXrxontc/x4wZI9u2bZMjR46YMPXggw9K3bp1zfB6AAAAn/cB6tmzp5w+fVomTpxogowOb9eaHWfH6JSUFDMyzGnRokVm9Nijjz7qdh2dR2jSpEmmSW3fvn0mUJ0/f950kNZ5grTGSJu6AAAAghwOh4Pb4E47QetosPT0dPoD3SJRcav5a3idI9N6cE8AoIh+fvu8CQwAAOBWIwABAADrEIAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDoEIAAAYB0CEAAAsA4BCAAAWKfQAWjLli1y9erVPMf1mD4HAAAQcAHovvvuk3PnzuU5np6ebp4DAAAIuADkcDgkKCgoz/GzZ89K6dKlvVUuAACAIlO8oCc+/PDD5k8NP/3795fQ0FDXc9euXZN9+/ZJmzZtiqaUAAAAvghA5cqVc9UAlS1bVkqWLOl6LiQkRFq1aiWDBw/2ZtkAAAB8G4Bee+0182dUVJSMHj2a5i4AAGBPH6D4+HjT/LVu3Tp5+eWX5cKFC+b48ePH5eLFi0VRRgAAAN/UADn98MMP0q1bN0lJSZGsrCz5zW9+Y5rEpk+fbvYTEhK8W0IAAABf1wCNGDFCmjVrJj/++KNbP6D/+Z//kfXr13u7fAAAAL6vAfrnP/8pn3/+uen4nJv2DTp27Jg3ywYAAOAfNUA5OTlm2Pv1jh49aprCAAAAAi4AdenSRebOneva13mBtPOzdo7+7W9/6+3yAQAA+L4JbNasWdK1a1epX7++XL58WX7/+99LUlKSREREyIoVK7xfQgAAAF8HoOrVq8vevXslMTHR/Km1P4MGDZI+ffq4dYoGAAAImABkXlS8uAk8ugEAAAR8H6A33nhDVq9e7dofO3aslC9f3qwDpnMEAQAABFwA+utf/+pq6tq6dassWLBAZsyYYfoAjRw5sijKCAAA4NsmsNTUVKlbt655vGrVKnn00UdlyJAh0rZtW+nYsaN3SwcAAOAPNUBlypSRs2fPmseffvqpWQpDhYWFyU8//eT9EgIAAPi6BkgDzx/+8Adp0qSJHD582DX3z9dff21mgwYAAAi4GqCFCxdK69at5fTp0/KPf/xDfvWrX5nju3btkt69exdFGQEAAHxbA6QjvrTj8/VeeOEFb5UJAADA/+YBUpcuXZKUlBTJzs52O96wYUNvlAsAAMB/ApA2ffXv31/Wrl3r8XlPC6UCAADc1n2Ann32WUlPT5ft27eb+YA0COnkiNHR0fLBBx8UTSkBAAB8WQO0YcMGef/996VZs2YSHBwsNWvWNCPDwsPDZerUqdKjRw9vlg8AAMD3NUCZmZlSqVIl87hChQqmSUw1aNBAdu/e7f0SAgAA+DoA1atXTw4dOmQeN2rUSF5++WU5duyYJCQkSJUqVbxdPgAAAN8HoBEjRsiJEyfM4/j4ePn444/lzjvvlHnz5pl1wm6Gzi2kkyjqbNItW7aUHTt25HvukiVLpH379qb2SbfOnTvnOd/hcMjEiRNNINN+SnpOUlLSTZUNAAAEnkIHoMcff9yMAlOxsbFmBfidO3eaNcJ69uxZ6AIkJibKqFGjTJjSJjStVerataucOnXK4/mbNm0yEy5u3LjRLMZao0YN6dKli6mFctLFWTWQaa2UdtYuXbq0uebly5cLXT4AABB4Ch2A/vKXv5g5gJxKlSolTZs2NSFDnyus2bNny+DBg2XAgAFSv359E1r0mkuXLvV4/vLly2XYsGHSuHFjiYmJkVdeeUVycnJk/fr1rtqfuXPnyvPPPy8PPvigmZdo2bJlcvz4cbN4KwAAQKEDkM74fPHixTzHNRQVdjZonURRl9DQJionHVmm+1q7UxD6vleuXJGKFSua/eTkZDl58qTbNcuVK2ea1vK7ZlZWlmRkZLhtAAAgcBU6AGkNS1BQUJ7je/fudYWQgjpz5oyZOLFy5cpux3VfQ0xBjBs3TqpWreoKPM7XFeaaOnxfQ5Jz02Y1AAAQuAo8D5B2ONbgo9tdd93lFoI0xGit0JNPPim30rRp02TlypWmX5B2oL5Z48ePN/2QnLQGiBAEAEDgKnAA0n41WvszcOBA09SlNSVOISEhZhSXrhJfGBEREVKsWDFJS0tzO677kZGRN3ztzJkzTQBat26d2/pjztfpNXIPy9d97TfkSWhoqNkAAIAdChyA+vXrZ/6sVauWtGnTRkqUKPGL31yDk44k0w7MDz30kDnm7NA8fPjwfF+no7xefPFF+eSTT8yM1Llp+TQE6TWcgUdrdHQ02NChQ39xmQEAgIVLYXTo0MH1WIeVX78avC6JURja9KThSoNMixYtTE2Tzjato8JU3759pVq1aqafjpo+fbqZ4+ett94ytU7Ofj1lypQxmzbN6XplU6ZMMeuTaSCaMGGC6SfkDFkAAMBuhQ5AOupq7Nix8vbbb8vZs2d/8WrwOneQLqehoUbDjNba6AKrzk7MKSkpZmSY06JFi0zoevTRR92uo/MITZo0yTzW8mmIGjJkiJw/f17atWtnrvlL+gkBAIDAEeTQjj2F8NRTT5lJCCdPnixPPPGEmcVZJyHUJTG0T06fPn3kdqdNZtrHSVe9L2yNFm5OVNxqbt11jkxjYWEAKKqf34WuAfrwww/NxIIdO3Y0zVS6LEXdunXNqvA6SWEgBCAAABDYCj0P0Llz56R27drmsaYr3VfazLRlyxbvlxAAAMDXAUjDj862rHQpCu0L5KwZKl++vLfLBwAA4PsApM1eOuuziouLM32AtHPxyJEjZcyYMd4vIQAAgJcVug+QBh0nXX7i4MGDZj0v7QeUe0JCAACAgAlA19POz7oBAAAEVACaN29egS/4zDPP/JLyAAAA+EcAmjNnjtu+TlyoEyI6Oz3rZIOlSpWSSpUqEYAAAEBgdILWUV/OTdfg0tmaDxw4YIbA66aPmzZtaiZHBAAACLhRYLqu1vz586VevXquY/pYa4mef/55b5cPAADA9wHoxIkTcvXqVY9rgKWlpXmrXAAAAP4TgDp16iR//OMfZffu3a5jOgx+6NChZlg8AABAwAWgpUuXSmRkpDRr1kxCQ0PN1qJFC7N6+yuvvFI0pQQAAPDlPEB33HGHrFmzRpKSkkznZ+eSGHfddZc3ywUAAOB/EyFGR0ebDQAAIOCbwAAAAG53BCAAAGAdAhAAALBOgQLQww8/LBkZGebxsmXLJCsrq6jLBQAA4NsA9NFHH0lmZqZ5PGDAAElPTy+6EgEAAPjDKDAd5j5+/Hi57777xOFwyNtvvy3h4eEez+3bt6+3ywgAAHDrA1BCQoKMGjVKVq9eLUFBQWbNL/3zenqMAAQAAAIiALVp00a2bdtmHgcHB8vhw4elUqVKRV02AAAA/xgFlpycbGaDBgAAsGYm6Jo1a8r58+fl1VdfdS2FUb9+fRk0aJCUK1euKMoIAADg2xqgL774QurUqSNz5syRc+fOmU0f67HcK8QDAAAETA3QyJEj5YEHHpAlS5ZI8eL/7+VXr16VP/zhD/Lss8/Kli1biqKcAAAAvgtAWgOUO/yYixQvLmPHjpVmzZp5r2QAAAD+0gSm8/+kpKTkOZ6amiply5b1VrkAAAD8JwD17NnTdHhOTEw0oUe3lStXmiaw3r17F00pAQAAfNkENnPmTNeEh9r3R5UoUUKGDh0q06ZN438OAAAIvAAUEhIiL730kkydOlW+++47c0xHgJUqVaooygcAAOD7AOSkgadBgwbeLQ0AAIA/9gECAAC43RGAAACAdQhAAADAOgQgAABgnZvqBJ2UlCQbN26UU6dOSU5OjttzEydO9FbZAAAA/CMA6TIYOudPRESEREZGmjmBnPQxAQgAAARcAJoyZYq8+OKLMm7cuKIpEQAAgL/1Afrxxx/lscceK5rSAAAA+GMA0vDz6aefFk1pAAAA/LEJrG7dujJhwgTZtm2bmQla1wHL7ZlnnvFm+QAAAHxfA7R48WIpU6aMbN68WRYsWCBz5sxxbXPnzi10ARYuXChRUVESFhYmLVu2lB07duR77tdffy2PPPKIOV87XHt6v0mTJpnncm8xMTGFLhcAAAhcha4BSk5O9tqbJyYmyqhRoyQhIcGEHw00Xbt2lUOHDkmlSpXynH/p0iWpXbu2aYYbOXJkvte95557ZN26da794sVveskzAAAQgH5RMnA4HObP3EPhC2P27NkyePBgGTBggNnXILR69WpZunSpxMXF5Tm/efPmZlOens8deHSIPnA7i4pbLf7iyLQevi4CAPh+Juhly5aZ/j8lS5Y0W8OGDeXNN98s1DWys7Nl165d0rlz5/8UJjjY7G/dulV+CZ2osWrVqqa2qE+fPpKSknLD87OysiQjI8NtAwAAgSv4ZmptdCLE3/72t/L222+brVu3bvLkk0+afkAFdebMGbl27ZpUrlzZ7bjunzx5Um6WNqW9/vrrsnbtWlm0aJFpsmvfvr1cuHAh39dMnTpVypUr59pq1Khx0+8PAAACsAls/vz5Jlj07dvXdeyBBx4w/W60A/KN+ubcCt27d3c91popDUQ1a9Y0QW3QoEEeXzN+/HjTF8lJa4AIQQAABK5CB6ATJ05ImzZt8hzXY/pcQelSGsWKFZO0tDS347rvzf475cuXl7vuuku+/fbbfM8JDQ01GwAAsEPwzcwDpLUpnkZ0RUdHF/g6ISEhEhsbK+vXr3cd04VVdb9169biLRcvXpTvvvtOqlSp4rVrAgAAy2qAXnjhBenZs6ds2bJF2rZta479+9//NsHFUzC6EW126tevnzRr1kxatGhhhsFnZma6RoVpM1u1atVMHx1nx+lvvvnG9fjYsWPy5ZdfmnmJNJip0aNHy/3332+avY4fPy7x8fGmpql3796F/agAACBAFToA6USE27dvNx2eV61aZY7dfffdZgLDJk2aFOpaGqROnz5tVpDXjs+NGzc2nZedHaN19JaODHPSQJP7PWbOnGm2Dh06yKZNm8yxo0ePmrBz9uxZueOOO6Rdu3Zm1mp9DAAAoIIczsl84NYJWkeDpaenS3h4OHfGsjlvkBfzAAEItJ/fxQt6QeeFfm6OHAIDAADwdwUKQBUqVDAjvHR5Ch1V5WnmZ61I0uM6tw8AAMBtH4A2bNggFStWNI83btxY1GUCAADwfQDSTsZOtWrVMpMEXl8LpDVAqamp3i8hAACAr+cB0gCkI7eud+7cOfMcAABAwAUgZ18fTxMOhoWFeatcAAAAvp8HyLlWloafCRMmSKlSpVzPacdnnRtI5/EBAAAImAC0Z88eVw3QV199ZZaycNLHjRo1MrMwAwAABEwAco7+0mUqXnrpJeb7AQAA9vQB0vW6rl696rET9M9NkggAAHBbBqBevXrJypUr8xzXhVD1OQAAgIALQNrZ+b777stzvGPHjuY5AACAgAtAWVlZHpvArly5Ij/99JO3ygUAAOA/AahFixayePHiPMcTEhIkNjbWW+UCAADw/SgwpylTpkjnzp1l79690qlTJ3Ns/fr1snPnTvn000+LoowAAAC+rQFq27atbN261awHph2fP/zwQ6lbt67s27dP2rdv793SAQAA+EMNkNIZn5cvX+790gAAAPhrAHK6fPmyZGdnux0LDw//pWUCAADwryawS5cuyfDhw6VSpUpSunRpqVChgtsGAAAQcAFozJgxsmHDBlm0aJGEhobKK6+8Ii+88IJUrVpVli1bVjSlBAAA8GUTmHZ61qCjEx/qumDa8Vk7QdesWdP0C+rTp483ywcAAOD7GiBd86t27dqu/j66r9q1aydbtmzxfgkBAAB8HYA0/CQnJ5vHMTExZii8s2aofPny3i4fAACA7wOQNnvpJIgqLi5OFi5cKGFhYTJy5EjTPwgAACDg+gBp0HHSGaEPHjwou3btMv2AGjZs6O3yAQAA+LYGSBc81eUvkpKSXMe08/PDDz9M+AEAAIEZgEqUKGGWvAAAALCqD9Djjz8ur776atGUBgAAwB/7AF29elWWLl0q69atk9jYWDMbdG6zZ8/2ZvkAAAB8H4D2798vTZs2NY8PHz7s9lxQUJD3SgYAAODrAPT9999LrVq1ZOPGjUVVFgAAAP/qAxQdHS2nT5927ffs2VPS0tKKqlwAAAC+D0AOh8Ntf82aNZKZmVkUZQIAAPCvUWAAAADWBCDt4Hx9J2c6PQMAgIDuBK1NYP3795fQ0FCzf/nyZXnyySfzDIN/9913vV9KAAAAXwSgfv365ZkQEQAAIKAD0GuvvVa0JQEAALhF6AQNAACsQwACAADWIQABAADrEIAAAIB1CEAAAMA6BCAAAGAdnweghQsXSlRUlISFhUnLli1lx44d+Z779ddfyyOPPGLO11mo586d+4uvCQAA7OPTAJSYmCijRo2S+Ph42b17tzRq1Ei6du0qp06d8nj+pUuXpHbt2jJt2jSJjIz0yjUBAIB9fBqAZs+eLYMHD5YBAwZI/fr1JSEhQUqVKiVLly71eH7z5s3lb3/7m/Tq1cu1JMcvvabKysqSjIwMtw0AAAQunwWg7Oxs2bVrl3Tu3Pk/hQkONvtbt269pdecOnWqlCtXzrXVqFHjpt4fAADcHnwWgM6cOSPXrl2TypUrux3X/ZMnT97Sa44fP17S09NdW2pq6k29PwAACLC1wAKZNqfl16QGAAACj89qgCIiIqRYsWKSlpbmdlz38+vg7ItrAgCAwOOzABQSEiKxsbGyfv1617GcnByz37p1a7+5JgAACDw+bQLT4er9+vWTZs2aSYsWLcy8PpmZmWYEl+rbt69Uq1bNdFJ2dnL+5ptvXI+PHTsmX375pZQpU0bq1q1boGsCAAD4NAD17NlTTp8+LRMnTjSdlBs3bixr1651dWJOSUkxo7icjh8/Lk2aNHHtz5w502wdOnSQTZs2FeiaAAAAQQ6Hw8FtcKfzAOlweB0RFh4ezu25BaLiVnOf/diRaT18XQQA8OrPb58vhQEAAHCrEYAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDoEIAAAYB0CEAAAsA4BCAAAWIcABAAArEMAAgAA1inu6wLAd6LiVnP7AQBWogYIAABYhwAEAACsQwACAADWIQABAADrEIAAAIB1GAXmA4y+AgDAt6gBAgAA1iEAAQAA6xCAAACAdQhAAADAOgQgAABgHQIQAACwDgEIAABYhwAEAACsQwACAADWIQABAADrEIAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDp+EYAWLlwoUVFREhYWJi1btpQdO3bc8Px33nlHYmJizPkNGjSQNWvWuD3fv39/CQoKctu6detWxJ8CAADcLnwegBITE2XUqFESHx8vu3fvlkaNGknXrl3l1KlTHs///PPPpXfv3jJo0CDZs2ePPPTQQ2bbv3+/23kaeE6cOOHaVqxYcYs+EQAA8HdBDofD4csCaI1P8+bNZcGCBWY/JydHatSoIU8//bTExcXlOb9nz56SmZkpH330ketYq1atpHHjxpKQkOCqATp//rysWrWqQGXIysoym1NGRoYpQ3p6uoSHh4u3RcWt9vo1gaJ0ZFoPbjAAv6c/v8uVK1egn98+rQHKzs6WXbt2SefOnf9ToOBgs79161aPr9Hjuc9XWmN0/fmbNm2SSpUqSb169WTo0KFy9uzZfMsxdepUc8Ocm4YfAAAQuHwagM6cOSPXrl2TypUrux3X/ZMnT3p8jR7/ufO1+WvZsmWyfv16mT59umzevFm6d+9u3suT8ePHm7To3FJTU73y+QAAgH8qLgGoV69ersfaSbphw4ZSp04dUyvUqVOnPOeHhoaaDQAA2MGnNUARERFSrFgxSUtLczuu+5GRkR5fo8cLc76qXbu2ea9vv/3WSyUHAAC3M58GoJCQEImNjTVNVU7aCVr3W7du7fE1ejz3+eqzzz7L93x19OhR0weoSpUqXiw9AAC4Xfl8GLwOgV+yZIm88cYbcuDAAdNhWUd5DRgwwDzft29f00fHacSIEbJ27VqZNWuWHDx4UCZNmiRffPGFDB8+3Dx/8eJFGTNmjGzbtk2OHDliwtKDDz4odevWNZ2lAQAAfN4HSIe1nz59WiZOnGg6Mutwdg04zo7OKSkpZmSYU5s2beStt96S559/Xv70pz9JdHS0Ge5+7733mue1SW3fvn0mUOlQ+KpVq0qXLl1k8uTJ9PMBAAD+MQ/Q7T6PwM1gHiDcbpgHCMDt4LaZBwgAAMAXCEAAAMA6BCAAAGAdn3eCBuD//KnfGv2RAHgDNUAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDoEIAAAYB0CEAAAsA4BCAAAWIcABAAArEMAAgAA1iEAAQAA6xCAAACAdQhAAADAOgQgAABgHQIQAACwDgEIAABYhwAEAACsQwACAADWIQABAADrEIAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAAIAANYhAAEAAOsQgAAAgHUIQAAAwDoEIAAAYJ3ivi4AABRGVNxqv7hhR6b18HURAPwC1AABAADrEIAAAIB1CEAAAMA6BCAAAGAdvwhACxculKioKAkLC5OWLVvKjh07bnj+O++8IzExMeb8Bg0ayJo1a9yedzgcMnHiRKlSpYqULFlSOnfuLElJSUX8KQAAwO3C5wEoMTFRRo0aJfHx8bJ7925p1KiRdO3aVU6dOuXx/M8//1x69+4tgwYNkj179shDDz1ktv3797vOmTFjhsybN08SEhJk+/btUrp0aXPNy5cv38JPBgAA/FWQQ6tLfEhrfJo3by4LFiww+zk5OVKjRg15+umnJS4uLs/5PXv2lMzMTPnoo49cx1q1aiWNGzc2gUc/TtWqVeW5556T0aNHm+fT09OlcuXK8vrrr0uvXr1+tkwZGRlSrlw587rw8HAJ1GG8AG4ew+AB/1OYn98+nQcoOztbdu3aJePHj3cdCw4ONk1WW7du9fgaPa41Rrlp7c6qVavM4+TkZDl58qS5hpPeDA1a+lpPASgrK8tsTnrjnDeyKORkXSqS6wK4de4c+Y7f3O79L3T1dREAv+D8uV2Quh2fBqAzZ87ItWvXTO1Mbrp/8OBBj6/RcOPpfD3ufN55LL9zrjd16lR54YUX8hzXmigA8Hfl5vq6BIB/uXDhgqn8uBFmghYxNVC5a5W0Ge7cuXPyq1/9SoKCgryeTjVYpaamFknz2u2Ie8I94e8K/374TuG71hu05kfDj3aF+Tk+DUARERFSrFgxSUtLczuu+5GRkR5fo8dvdL7zTz2mo8Byn6P9hDwJDQ01W27ly5eXoqThhwDEPeHvCf9++E7he/ZWC/SfP+V+pubHL0aBhYSESGxsrKxfv96t9kX3W7du7fE1ejz3+eqzzz5znV+rVi0TgnKfozUMOhosv2sCAAC7+LwJTJue+vXrJ82aNZMWLVrI3LlzzSivAQMGmOf79u0r1apVM/101IgRI6RDhw4ya9Ys6dGjh6xcuVK++OILWbx4sXlem6yeffZZmTJlikRHR5tANGHCBFMdpsPlAQAAfB6AdFj76dOnzcSF2klZm6nWrl3r6sSckpJiRoY5tWnTRt566y15/vnn5U9/+pMJOToC7N5773WdM3bsWBOihgwZIufPn5d27dqZa+rEib6mTW0659H1TW42455wT/i7wr8fvlP4rrVuHiAAAADrZoIGAAC41QhAAADAOgQgAABgHQIQAACwDgHoFlq4cKFERUWZ0Wi6NtmOHTvEZjq1gS6EW7ZsWalUqZKZpuDQoUO+LpZfmTZtmmtqB5sdO3ZMHn/8cTM7e8mSJaVBgwZm+gub6TJCOsWHTvWh96ROnToyefLkAq2BFCi2bNki999/v5nmRP+dONeEdNJ7oSOMdVJcvUe6RmRSUpLYfF+uXLki48aNM/+GSpcubc7R6WaOHz8utiEA3SKJiYlmziMdAr97925p1KiRWcT11KlTYqvNmzfLU089Jdu2bTOTWeo/zC5dupgpDCCyc+dOefnll6Vhw4ZW344ff/xR2rZtKyVKlJCPP/5YvvnmGzMPWIUKFcRm06dPl0WLFsmCBQvkwIEDZn/GjBkyf/58sYV+V+h3qf5y6Ynej3nz5klCQoKZDFd/4Ov37uXLl8XW+3Lp0iXzM2jChAnmz3fffdf84vnAAw+IdXQYPIpeixYtHE899ZRr/9q1a46qVas6pk6dyu3//06dOqW/ujo2b95s/T25cOGCIzo62vHZZ585OnTo4BgxYoS192TcuHGOdu3a+boYfqdHjx6OgQMHuh17+OGHHX369HHYSL873nvvPdd+Tk6OIzIy0vG3v/3Ndez8+fOO0NBQx4oVKxy23hdPduzYYc774YcfHDahBugWyM7Oll27dpnqVyed3FH3t27deiuKcFtIT083f1asWFFspzVjOtN57r8ztvrggw/MTPGPPfaYaSpt0qSJLFmyRGynk8Lqkj+HDx82+3v37pV//etf0r17d18XzS8kJyebyXVz/xvSNaK0+wHfu+70u1ebyop6DUx/4/OZoG1w5swZ017vnN3aSfcPHjzos3L5E10DTvu5aFNH7lm9baTLu2jVtDaBQeT77783TT3ahKyzv+t9eeaZZ8xagrqMjq3i4uLMOocxMTFmUWn9jnnxxRelT58+vi6aX9Dwozx97zqfg5jmQO0T1Lt374BeINUTAhD8psZj//795jdYm6Wmppr17rRPlD8s3eIv4VhrgP7617+afa0B0r8r2q/D5gD09ttvy/Lly83SQPfcc498+eWX5pcI7dRq831BwV25ckV+97vfmc7i+kuGbWgCuwUiIiLMb2hpaWlux3VfV6633fDhw+Wjjz6SjRs3SvXq1cVm2lSqHeObNm0qxYsXN5t2FteOnPpYf8u3jY7gqV+/vtuxu+++26wTaLMxY8aYWqBevXqZET1PPPGEjBw50rVwtO2c36187944/Pzwww/mFy7ban8UAegW0Kr62NhY016f+7da3W/durXYSn/r0PDz3nvvyYYNG8xwXtt16tRJvvrqK/PbvHPT2g9t1tDHGqRto82i10+PoP1eatasKTbT0Ty5F4pW+vdDv1sg5vtEQ1Du711tMtTRYDZ/7+YOP0lJSbJu3TozvYSNaAK7RbT/glZL6w+zFi1ayNy5c81QxQEDBojNzV5aff/++++buYCc7fLaUVHn7LCR3ofr+0Dp0F39grK1b5TWamiHX20C0y9tnT9r8eLFZrOZzvOifX7uvPNO0wS2Z88emT17tgwcOFBscfHiRfn222/dOj7rLwo6kELvizYJTpkyRaKjo00g0qHf2kSoc47Zel+0RvXRRx81/Qy15l1rlZ3fvfq8/sJuDV8PQ7PJ/PnzHXfeeacjJCTEDIvftm2bw2b618/T9tprr/m6aH7F9mHw6sMPP3Tce++9ZghzTEyMY/HixQ7bZWRkmL8X+p0SFhbmqF27tuPPf/6zIysry2GLjRs3evwO6devn2so/IQJExyVK1c2f3c6derkOHTokMPm+5KcnJzvd+/GjRsdNgnS//g6hAEAANxK9AECAADWIQABAADrEIAAAIB1CEAAAMA6BCAAAGAdAhAAALAOAQgAAFiHAAQAAKxDAALgN44cOSJBQUFm2n5/cfDgQWnVqpWEhYVJ48aNPZ7TsWNHs+xCQW3atMl8zvPnz/+iskVFRZlldQAUHgEIgEv//v3ND+Zp06a53ZVVq1aZ4zaKj48367Hpgqy5F9YEcHsjAAFwozUd06dPlx9//DFg7kx2dvZNv/a7776Tdu3amdXnbV01GwhEBCAAbjp37iyRkZEyderUfO/MpEmT8jQHaVOMNsnkrk3SVbd1FffKlStL+fLl5S9/+YtcvXpVxowZY1aerl69urz22msem510BXgNY/fee69s3rzZ7fn9+/dL9+7dpUyZMubaTzzxhJw5c8atSWr48OGmWSoiIkK6du3q8XPk5OSYMmk5QkNDzWdau3at63mt9dq1a5c5Rx/r5y6IN998U5o1ayZly5Y19/L3v/+9nDp1Ks95//73v6Vhw4bmc2ozm36u3P71r39J+/btpWTJklKjRg155plnJDMz0+N76rKOWj5dBV0/i656rucD8IwABMBNsWLFTGiZP3++HD169BfdnQ0bNsjx48dly5YtMnv2bNOc9N///d9SoUIF2b59uzz55JPyxz/+Mc/7aEB67rnnZM+ePdK6dWu5//775ezZs+Y57TfzX//1X9KkSRP54osvTGBJS0uT3/3ud27XeOONNyQkJMSEjISEBI/le+mll2TWrFkyc+ZM2bdvnwlKDzzwgCQlJZnnT5w4Iffcc48piz4ePXp0gT73lStXZPLkybJ3717TfKh9mzQQXk8/p77/zp075Y477jCfU1/rrHnq1q2bPPLII6ZsiYmJJhBpsPPkH//4h8yZM0defvllU3593wYNGhSovICVfL0cPQD/0a9fP8eDDz5oHrdq1coxcOBA8/i9995z5P66iI+PdzRq1MjttXPmzHHUrFnT7Vq6f+3aNdexevXqOdq3b+/av3r1qqN06dKOFStWmP3k5GTzPtOmTXOdc+XKFUf16tUd06dPN/uTJ092dOnSxe29U1NTzesOHTpk9jt06OBo0qTJz37eqlWrOl588UW3Y82bN3cMGzbMta+fUz/vjej7jRgxIt/nd+7cacp34cIFs79x40azv3LlStc5Z8+edZQsWdKRmJho9gcNGuQYMmSI23X++c9/OoKDgx0//fST2df7q/ddzZo1y3HXXXc5srOzf/ZzA3A4qAEC4JH2A9JalAMHDtz0HdLak+Dg/3zNaHNV7loJrW3SfjXXNw9prY9T8eLFTXOSsxxaq7Jx40bT/OXcYmJiXLUmTrGxsTcsW0ZGhqmdatu2rdtx3f8ln1lps5nW5mhzlDaDdejQwRxPSUnJ93Nqk2C9evXcPufrr7/u9jm1hkqb7ZKTk/O852OPPSY//fST1K5dWwYPHizvvfeeaW4E4BkBCIBHv/71r80P3PHjx+f94ggONn1OcnM23eRWokQJt33tR+PpmP5QL6iLFy+acKFD5XNv2uyjZXbSkVu+oH109L6Fh4fL8uXLTfOWhpHCdsbWz6nNg7k/o4Yi/Zx16tTJc772EdKRav/7v/9r+gwNGzbM3A9P/18AiBTnJgDIjw6H147BWjORm/ZXOXnypAlBzuHx3py7Z9u2ba4wo7UYWqPi7PvStGlT099FO1xr7dDN0oCiHYW1j5CzhkbpfosWLW76utqBW/sr6b3TUKK0r1J+n1NriZSOujt8+LDcfffdrs/5zTffSN26dQv83hp8NBzq9tRTT5masa+++spcC4A7aoAA5Eubq/r06SPz5s1zO66jrE6fPi0zZswwzU4LFy6Ujz/+2Gt3Uq+ntSYaJvQHuYaDgQMHmud0/9y5c9K7d29Tu6Lv/8knn8iAAQPk2rVrhXof7YSsTX3awVhrT+Li4kyQGzFixE2XXQONdr7WTuTff/+9fPDBB6ZDtCc6ukznFtLRX9pJWkes6cg5NW7cOPn8889N8HPWcL3//vv5doLW5rJXX33VXEvf9+9//7sJRDp8H0BeBCAAN6Q/pK9votJaCm1q0aDSqFEj2bFjR4FHSBWE1p7optfWkU8aIjQcKGetjYadLl26mJCmw911mH3u/kYFocPER40aZUZ56XV0RJm+V3R09E2XXWvHNIy88847Ur9+ffM5dJRZfp9Tw5b2V9IatQ8//NCEJ6XD43X4v9YK6VB4HfU2ceJE8/k90c+/ZMkS04dJX7tu3TpzPeYuAjwL0p7g+TwHAAAQkKgBAgAA1iEAAQAA6xCAAACAdQhAAADAOgQgAABgHQIQAACwDgEIAABYhwAEAACsQwACAADWIQABAADrEIAAAIDY5v8AwNvPzImeRvoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_label_frequency(L):\n",
    "    plt.hist((L != ABSTAIN).sum(axis=1), density=True, bins=range(L.shape[1]))\n",
    "    plt.xlabel(\"Number of labels\")\n",
    "    plt.ylabel(\"Fraction of dataset\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_label_frequency(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "We see that over half of our `train` dataset data points have 2 or fewer labels from LFs. Fortunately, the labels we do have can be used to train a classifier over the review text directly, allowing this final machine learning model to generalize beyond what our labeling functions label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is now to convert the labels from our LFs into a single _noise-aware_ probabilistic (or confidence-weighted) label per data point.\n",
    "A simple baseline for doing this is to take the majority vote across the LFs for each data point.\n",
    "However, different LFs have different accuracies, so giving them all equal weight is not ideal.\n",
    "Instead, we'll use Snorkel's `LabelModel` to learn how to weight each LF for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, ...,  1,  1,  1], shape=(4000,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we can see from the summary statistics of our LFs in the previous section, they have varying properties and should not be treated identically. In addition to having varied accuracies and coverages, LFs may be correlated, resulting in certain signals being overrepresented in a majority-vote-based model. To handle these issues appropriately, we will instead use a more sophisticated Snorkel `LabelModel` to combine the outputs of the LFs.\n",
    "\n",
    "This model will ultimately produce a single set of noise-aware training labels, which are probabilistic or confidence-weighted labels. We will then use these labels to train a classifier for our task. For more technical details of this overall approach, see our [NeurIPS 2016](https://arxiv.org/abs/1605.07723) and [AAAI 2019](https://arxiv.org/abs/1810.02840) papers. For more info on the API, see the [`LabelModel` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.label_model.LabelModel.html#snorkel.labeling.model.label_model.LabelModel).\n",
    "\n",
    "Note that no gold labels are used during the training process.\n",
    "The only information we need is the label matrix, which contains the output of the LFs on our training set.\n",
    "The `LabelModel` is able to learn weights for the labeling functions using only the label matrix as input.\n",
    "We also specify the `cardinality`, or number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=1.396]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[200 epochs]: TRAIN:[loss=0.002]\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 217/500 [00:00<00:00, 2164.48epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.002]\n",
      "INFO:root:[400 epochs]: TRAIN:[loss=0.002]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 2746.93epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   56.9%\n",
      "Label Model Accuracy:     52.3%\n"
     ]
    }
   ],
   "source": [
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority vote model or more sophisticated `LabelModel` could in principle be used directly as a classifier if the outputs of our labeling functions were made available at test time.\n",
    "However, these models (i.e. these re-weighted combinations of our labeling function's votes) will abstain on the data points that our labeling functions don't cover (and additionally, may require slow or unavailable features to execute at test time).\n",
    "In the next section, we will instead use the outputs of the `LabelModel` as training labels to train a discriminative classifier **which can generalize beyond the labeling function outputs** to see if we can improve performance further.\n",
    "This classifier will also only need the text of the review to make predictions, making it much more suitable for inference over unseen reviews.\n",
    "For more information on the properties of the label model, see the [Snorkel documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.label_model.LabelModel.html#snorkel.labeling.model.label_model.LabelModel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "Let's briefly confirm that the labels the `LabelModel` produces are indeed probabilistic in nature.\n",
    "The following histogram shows the confidences we have that each data point has the label POSITIVE.\n",
    "The plot highlights that we get a broad range of probability estimates rather than just a hard label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_probabilities_histogram(Y):\n",
    "    plt.hist(Y, bins=10)\n",
    "    plt.xlabel(\"Probability of POSITIVE\")\n",
    "    plt.ylabel(\"Number of data points\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "plot_probabilities_histogram(probs_train[:, POSITIVE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out unlabeled data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier, some of the data points in our `train` set received no labels from any of our LFs.\n",
    "These data points convey no supervision signal and tend to hurt performance, so we filter them out before training using a\n",
    "[built-in utility](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.filter_unlabeled_dataframe.html#snorkel.labeling.filter_unlabeled_dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final section of the tutorial, we'll use the probabilistic training labels we generated in the last section to train a classifier for our task.\n",
    "**The output of the Snorkel `LabelModel` is just a set of labels which can be used with most popular libraries for performing supervised learning, such as TensorFlow, Keras, PyTorch, Scikit-Learn, Ludwig, and XGBoost.**\n",
    "In this tutorial, we use the well-known library [Scikit-Learn](https://scikit-learn.org).\n",
    "**Note that typically, Snorkel is used (and really shines!) with much more complex, training data-hungry models, but we will use Logistic Regression here for simplicity of exposition.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** An ML model requires numerical features. So, we convert the reviews (text format) into numerical format using one of the many methods called \"bag of n-grams\". You will learn more about such methods and representations in Natural Language Processing (NLP).\n",
    "\n",
    "For simplicity and speed, we use a simple \"bag of n-grams\" feature representation: each data point is represented by a one-hot vector marking which words or 2-word combinations are present in the review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
    "X_test = vectorizer.transform(df_test.text.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in Section 4, the `LabelModel` outputs probabilistic (float) labels.\n",
    "If the classifier we are training accepts target labels as floats, we can train on these labels directly (see describe the properties of this type of \"noise-aware\" loss in our [NeurIPS 2016 paper](https://arxiv.org/abs/1605.07723)).\n",
    "\n",
    "If we want to use a library or model that doesn't accept probabilistic labels (such as Scikit-Learn), we can instead replace each label distribution with the label of the class that has the maximum probability.\n",
    "This can easily be done using the\n",
    "[`probs_to_preds` helper method](https://snorkel.readthedocs.io/en/master/packages/_autosummary/utils/snorkel.utils.probs_to_preds.html#snorkel.utils.probs_to_preds).\n",
    "We do note, however, that this transformation is lossy, as we no longer have values for our confidence in each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use these labels to train a classifier as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15400789, 0.84599211],\n",
       "       [0.13942295, 0.86057705],\n",
       "       [0.15400789, 0.84599211],\n",
       "       ...,\n",
       "       [0.13078905, 0.86921095],\n",
       "       [0.15260273, 0.84739727],\n",
       "       [0.16920932, 0.83079068]], shape=(3711, 2))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000.0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1000.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;liblinear&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(C=1000.0, solver='liblinear')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=1e3, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=preds_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 50.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {sklearn_model.score(X=X_test, y=Y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe an additional boost in accuracy over the `LabelModel` by multiple points! This is in part because the discriminative model generalizes beyond the labeling function's labels and makes good predictions on all data points, not just the ones covered by labeling functions.\n",
    "By using the label model to transfer the domain knowledge encoded in our LFs to the discriminative model,\n",
    "we were able to generalize beyond the noisy labeling heuristics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we accomplished the following:\n",
    "* We introduced the concept of Labeling Functions (LFs) and demonstrated some of the forms they can take.\n",
    "* We used the Snorkel `LabelModel` to automatically learn how to combine the outputs of our LFs into strong probabilistic labels.\n",
    "* We showed that a classifier trained on a weakly supervised dataset can outperform an approach based on the LFs alone as it learns to generalize beyond the noisy heuristics we provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you enjoyed this tutorial and you've already checked out the [Getting Started](https://snorkel.org/get-started/) tutorial, check out the [Tutorials](https://snorkel.org/use-cases/) page for other tutorials that you may find interesting, including demonstrations of how to use Snorkel\n",
    "\n",
    "* As part of a [hybrid crowdsourcing pipeline](https://snorkel.org/use-cases/crowdsourcing-tutorial)\n",
    "* For [visual relationship detection over images](https://snorkel.org/use-cases/visual-relation-tutorial)\n",
    "* For [information extraction over text](https://snorkel.org/use-cases/spouse-demo)\n",
    "* For [data augmentation](https://snorkel.org/use-cases/02-positive-data-augmentation-tutorial)\n",
    "\n",
    "and more!\n",
    "You can also visit the [Snorkel website](https://snorkel.org) or [Snorkel API documentation](https://snorkel.readthedocs.io) for more info!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "lab3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
